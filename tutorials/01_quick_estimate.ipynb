{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: A Quick First Estimate\n",
    "\n",
    "This notebook covers the most basic use case of the `NeuralMI` library: getting a single, quick estimate of mutual information between two variables.\n",
    "\n",
    "**Goal:**\n",
    "1.  Introduce the main `neural_mi.run` function.\n",
    "2.  Use a simple dataset where the ground truth MI is known analytically.\n",
    "3.  Compare our estimate to the ground truth to verify the library is working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "We'll need `torch` for data handling, our `run` function, and the data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import neural_mi as nmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generating the Data\n",
    "\n",
    "We will use the `generate_correlated_gaussians` function from the `datasets` module. This function creates two multidimensional Gaussian variables, `X` and `Y`, where we can precisely specify the mutual information between them in **bits**.\n",
    "\n",
    "The analytical formula for MI between two multivariate Gaussians is:\n",
    "\n",
    "$$ I(X;Y) = -\\frac{1}{2} \\log_2 \\det(\\Sigma_{XY}) $$\n",
    "\n",
    "Where $\\Sigma_{XY}$ is the correlation matrix. Our generator function handles this for us. Let's create data with a known MI of **2.0 bits**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset Parameters ---\n",
    "n_samples = 5000\n",
    "dim = 5\n",
    "ground_truth_mi_bits = 2.0\n",
    "\n",
    "# --- Generate Data ---\n",
    "x_data, y_data = nmi.datasets.generate_correlated_gaussians(\n",
    "    n_samples=n_samples, \n",
    "    dim=dim, \n",
    "    mi=ground_truth_mi_bits\n",
    ")\n",
    "\n",
    "# Reshape for the library: [n_samples, n_channels, n_features]\n",
    "# In this simple case, we have 1 channel and 'dim' features.\n",
    "x_data = x_data.reshape(n_samples, 1, dim)\n",
    "y_data = y_data.reshape(n_samples, 1, dim)\n",
    "\n",
    "print(f\"Generated X data shape: {x_data.shape}\")\n",
    "print(f\"Generated Y data shape: {y_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining the Analysis Parameters\n",
    "\n",
    "The `run` function requires a `base_params` dictionary. This tells the internal `Trainer` how to configure the neural network and the training process. For a quick estimate, we don't need to be too fussy, but we still need to provide the essentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = {\n",
    "    'n_epochs': 50,          # Number of training epochs\n",
    "    'learning_rate': 1e-3,   # Learning rate for the optimizer\n",
    "    'batch_size': 128,       # Batch size for training\n",
    "    'patience': 5,           # Early stopping patience\n",
    "    \n",
    "    # --- Network Architecture ---\n",
    "    'embedding_dim': 16,     # Dimensionality of the learned embeddings\n",
    "    'hidden_dim': 64,        # Number of units in hidden layers\n",
    "    'n_layers': 2            # Number of hidden layers in the MLP\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running the MI Estimation\n",
    "\n",
    "Now we call the main `nmi.run` function. We specify `mode='estimate'` for a single run with the fixed parameters we defined above.\n",
    "\n",
    "By default, the function returns the MI value in **bits**, which is convenient for comparison with our ground truth. You can request 'nats' by setting `output_units='nats'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_mi_bits = nmi.run(\n",
    "    x_data=x_data,\n",
    "    y_data=y_data,\n",
    "    mode='estimate',\n",
    "    base_params=base_params,\n",
    "    output_units='bits' # This is the default, but we're explicit here.\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Results ---\")\n",
    "print(f\"Ground Truth MI:      {ground_truth_mi_bits:.3f} bits\")\n",
    "print(f\"Estimated MI:         {estimated_mi_bits:.3f} bits\")\n",
    "print(f\"Estimation Error:     {abs(estimated_mi_bits - ground_truth_mi_bits):.3f} bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "Success! The estimated MI is very close to the ground truth value we specified. This confirms that the core estimation engine is working correctly.\n",
    "\n",
    "In the next example, we'll tackle a more complex problem where the relationship between X and Y isn't instantaneous, introducing the need to process our data before estimation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
