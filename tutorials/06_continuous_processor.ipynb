{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6: A Deep Dive into the ContinuousProcessor\n",
    "\n",
    "Previous tutorials showed how to use `processor_type='continuous'` inside the `nmi.run()` function for automated processing. This notebook provides a more detailed look at what the `ContinuousProcessor` is actually doing under the hood.\n",
    "\n",
    "**Goal:**\n",
    "1.  Understand the role of `window_size` and `step_size`.\n",
    "2.  Manually use the `ContinuousProcessor` to see how it transforms data.\n",
    "3.  Show how this process relates to the simplified `nmi.run()` workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import neural_mi as nmi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generating Raw Time-Series Data\n",
    "\n",
    "First, let's create a simple, raw time-series dataset. We'll make it shape `(n_timepoints, n_channels)` to simulate a typical recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timepoints = 100\n",
    "n_channels = 3\n",
    "\n",
    "x_raw = np.random.randn(n_timepoints, n_channels)\n",
    "y_raw = np.random.randn(n_timepoints, n_channels)\n",
    "\n",
    "print(f\"Raw data shape: {x_raw.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Manual Processing\n",
    "\n",
    "The `ContinuousProcessor` takes a 2D array of shape `(n_channels, n_timepoints)` and converts it into a 3D array of shape `(n_samples, n_channels, window_size)`. Let's see this in action.\n",
    "\n",
    "- `window_size`: The number of timepoints to include in each sample.\n",
    "- `step_size`: The number of timepoints to slide the window forward for the next sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The processor expects shape (n_channels, n_timepoints), so we transpose our raw data.\n",
    "# The DataHandler inside nmi.run does this automatically with a heuristic.\n",
    "x_raw_transposed = x_raw.T\n",
    "print(f\"Transposed raw data shape: {x_raw_transposed.shape}\\n\")\n",
    "\n",
    "# Initialize the processor\n",
    "processor = nmi.data.ContinuousProcessor(window_size=10, step_size=1)\n",
    "\n",
    "# Process the data\n",
    "x_processed = processor.process(x_raw_transposed)\n",
    "\n",
    "print(f\"Processed data shape: {x_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shape `(91, 3, 10)` makes sense:\n",
    "- **91 samples**: We started with 100 timepoints. The last possible window of size 10 starts at index 90. With a step size of 1, this gives us 91 total windows (from index 0 to 90).\n",
    "- **3 channels**: The number of channels is preserved.\n",
    "- **10 features**: Each sample (window) now contains 10 timepoints, which are treated as features by the MI estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Simplified Workflow\n",
    "\n",
    "While you *can* process the data manually as shown above, you don't need to. The `nmi.run` function does this for you when you provide the `processor_type` and `processor_params`. It even handles the transposition for you.\n",
    "\n",
    "The following code achieves the same result as our manual processing, but in a single, clean step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = {\n",
    "    'n_epochs': 5, 'learning_rate': 1e-3, 'batch_size': 32,\n",
    "    'patience': 2, 'embedding_dim': 8, 'hidden_dim': 32, 'n_layers': 1\n",
    "}\n",
    "\n",
    "results = nmi.run(\n",
    "    x_data=x_raw, # Pass the raw [time, channel] data\n",
    "    y_data=y_raw,\n",
    "    mode='estimate',\n",
    "    processor_type='continuous',\n",
    "    processor_params={'window_size': 10, 'step_size': 1},\n",
    "    base_params=base_params\n",
    ")\n",
    "\n",
    "print(f\"\\nMI Estimate from automated pipeline: {results.mi_estimate:.3f} bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "This tutorial demystified the `ContinuousProcessor`. By understanding how it windows data, you can now more effectively choose the `window_size` and `step_size` parameters when performing sweeps to find the characteristic timescale of your data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}